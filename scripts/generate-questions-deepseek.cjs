const { createClient } = require('@supabase/supabase-js');
const OpenAI = require('openai');
const path = require('path');
const fs = require('fs');
require('dotenv').config({ path: path.resolve(__dirname, '../.env') });

// Configuration
const SUPABASE_URL = process.env.VITE_SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.VITE_SUPABASE_ANON_KEY;
const DEEPSEEK_API_KEY = process.env.VITE_DEEPSEEK_API_KEY;

if (!SUPABASE_URL || !SUPABASE_KEY) {
  console.error('‚ùå Supabase credentials missing in .env');
  process.exit(1);
}

if (!DEEPSEEK_API_KEY) {
  console.error('‚ùå DeepSeek API key missing in .env');
  process.exit(1);
}

const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);

const openai = new OpenAI({
  apiKey: DEEPSEEK_API_KEY,
  baseURL: 'https://api.deepseek.com',
});

async function generateQuestions(transcriptData, episodeLang) {
  console.log(`ü§ñ Generating questions for lang: ${episodeLang}`);

  // Prepare text
  const utterances = transcriptData.utterances || [];
  let textToAnalyze = '';

  // DeepSeek V3 has a large context window (64k tokens). 
  // We can send a significant amount of text.
  // Assuming avg 20 tokens per utterance, 2500 utterances is ~50k tokens.
  const MAX_UTTERANCES = 2500;
  
  const segmentsToAnalyze = utterances.slice(0, MAX_UTTERANCES);
  
  textToAnalyze = segmentsToAnalyze.map((utterance) => {
    const timeInSeconds = Math.floor(utterance.start / 1000);
    const speakerInfo = utterance.speaker ? `[${utterance.speaker}]` : '';
    const text = utterance.text || '';
    return `[${timeInSeconds}s]${speakerInfo} ${text}`;
  }).join('\n');

  console.log(`üìù Analyzing ${segmentsToAnalyze.length} segments (${textToAnalyze.length} chars)`);

  const langMap = {
    'ru': { name: '—Ä—É—Å—Å–∫–æ–º', prompt: 'russian' },
    'es': { name: '–∏—Å–ø–∞–Ω—Å–∫–æ–º', prompt: 'spanish' },
    'en': { name: '–∞–Ω–≥–ª–∏–π—Å–∫–æ–º', prompt: 'english' }
  };
  const langConfig = langMap[episodeLang] || langMap['en'];

  const systemPrompt = `You are an expert content analyst specializing in multilingual podcast analysis. Your task is to identify key questions, topics, and discussions from healing/healer podcasts where people ask questions about health, wellness, and life advice.

IMPORTANT CONTEXT:
- The podcast has multiple listeners, a healer, and a translator
- Different speakers are labeled with letters (A, B, C, etc.)
- The translator translates questions from listeners and answers from the healer
- You need to identify ORIGINAL questions from listeners, not translations
- The transcript format includes timing markers: [125s][A] means 125 seconds, speaker A

STRATEGY: Focus on identifying NEW questions or topics that start new discussion threads. Look for:
- When a NEW listener starts speaking about a different problem/topic
- Changes in conversation direction to a new issue/question
- New questions that haven't been discussed before
- Different aspects of the same general topic (but as separate questions)
- Pay attention to speaker changes - new speakers often indicate new questions
- Look for explicit question markers like "–≤–æ–ø—Ä–æ—Å –æ—Ç", "—Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å", "–æ—á–µ—Ä–µ–¥–Ω–æ–π —Å–ª—É—à–∞—Ç–µ–ª—å", "question from", "next question"
- Pay special attention to phrases that introduce new listeners or their problems
- MEDITATIONS: Look for when the healer starts guided meditations at the end of Q&A sessions
- Look for meditation phrases like "–¥–∞–≤–∞–π—Ç–µ –º–µ–¥–∏—Ç–∏—Ä–æ–≤–∞—Ç—å", "–∑–∞–∫—Ä–æ–π—Ç–µ –≥–ª–∞–∑–∞", "let's meditate", "close your eyes", "deep breathing"

For each identified question/topic/meditation:
1. Find the EXACT moment when this question/topic/meditation FIRST appears in the conversation
2. Look for the ORIGINAL question from the listener (not the translation)
3. Create a concise title (3-8 words) that captures the essence of the question/topic/meditation
4. For MEDITATIONS: Create titles like "Guided Meditation", "Relaxation Exercise", "Breathing Practice", etc.
5. CRITICAL: Extract the time from the [time] markers in the transcript (e.g., [125s] means 125 seconds)
6. Use the timestamp from the very first utterance where this topic/question/meditation begins

Return ONLY a valid JSON array in this format:
[
  {
    "title": "–ö—Ä–∞—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤–æ–ø—Ä–æ—Å–∞/–º–µ–¥–∏—Ç–∞—Ü–∏–∏ –Ω–∞ ${langConfig.name} —è–∑—ã–∫–µ",
    "time": —Ç–æ—á–Ω–æ–µ_–≤—Ä–µ–º—è_–≤_—Å–µ–∫—É–Ω–¥–∞—Ö_–∏–∑_–ø–µ—Ä–≤–æ–≥–æ_—Å–µ–≥–º–µ–Ω—Ç–∞_—Ç–µ–º—ã
  }
]

Guidelines:
- Extract as many important questions/topics/MEDITATIONS as possible (aim for 10-30+ for longer podcasts)
- Focus on genuine questions about health, relationships, personal growth, etc.
- INCLUDE MEDITATIONS: Look for guided meditations, relaxation exercises, breathing practices
- PRIORITY: Identify questions from different listeners (different speakers)
- Pay attention to speaker changes - new speaker = potentially new question
- Ignore meta-discussion about the podcast itself and technical issues
- Ignore translations - focus on original questions from listeners and original meditations
- TIME CRITICAL: Extract time from [time] markers (e.g., [125s] = 125 seconds)
- Time should be from the FIRST utterance of each question/topic/meditation (usually when the listener starts speaking or healer starts meditation)
- If you can't find exact timing markers, estimate based on text position
- Ensure titles are concise but descriptive
- Return only the JSON array, no additional text`;

  const userPrompt = `–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç –ø–æ–¥–∫–∞—Å—Ç–∞ —Å —Ü–µ–ª–∏—Ç–µ–ª–µ–º –∏ –Ω–∞–π–¥–∏ –∫–ª—é—á–µ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ —Ç–µ–º—ã:

${textToAnalyze}

–í–ù–ò–ú–ê–ù–ò–ï: –¢–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [–≤—Ä–µ–º—è] –∏ –º–µ—Ç–∫–∏ —Å–ø–∏–∫–µ—Ä–æ–≤ [A], [B] –∏ —Ç.–¥.

–í –ø–æ–¥–∫–∞—Å—Ç–µ —É—á–∞—Å—Ç–≤—É—é—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª—É—à–∞—Ç–µ–ª–µ–π –∏ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫. –ò—â–∏:

1. –ù–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –æ—Ç —Ä–∞–∑–Ω—ã—Ö —Å–ª—É—à–∞—Ç–µ–ª–µ–π (—Ä–∞–∑–Ω—ã–µ –º–µ—Ç–∫–∏ —Å–ø–∏–∫–µ—Ä–æ–≤ [A], [B], [C]...)
2. –ö–æ–≥–¥–∞ –Ω–æ–≤—ã–π —Å–ª—É—à–∞—Ç–µ–ª—å –Ω–∞—á–∏–Ω–∞–µ—Ç –≥–æ–≤–æ—Ä–∏—Ç—å –æ —Å–≤–æ–µ–π –ø—Ä–æ–±–ª–µ–º–µ
3. –ü–µ—Ä–µ—Ö–æ–¥—ã –∫ –Ω–æ–≤—ã–º —Ç–µ–º–∞–º –≤ –æ—Ç–≤–µ—Ç–∞—Ö —Ü–µ–ª–∏—Ç–µ–ª—è
4. –ú–ï–î–ò–¢–ê–¶–ò–ò: –ö–æ–≥–¥–∞ —Ü–µ–ª–∏—Ç–µ–ª—å –Ω–∞—á–∏–Ω–∞–µ—Ç –ø—Ä–æ–≤–æ–¥–∏—Ç—å –º–µ–¥–∏—Ç–∞—Ü–∏–∏
5. –ò—â–∏ —Ñ—Ä–∞–∑—ã: "–≤–æ–ø—Ä–æ—Å –æ—Ç", "—Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å", "–æ—á–µ—Ä–µ–¥–Ω–æ–π —Å–ª—É—à–∞—Ç–µ–ª—å", "–¥–∞–≤–∞–π—Ç–µ –º–µ–¥–∏—Ç–∏—Ä–æ–≤–∞—Ç—å", "–∑–∞–∫—Ä–æ–π—Ç–µ –≥–ª–∞–∑–∞"
6. –û–°–û–ë–û–ï –í–ù–ò–ú–ê–ù–ò–ï: –º–µ–¥–∏—Ç–∞—Ü–∏–∏ —á–∞—Å—Ç–æ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –í –ö–û–ù–¶–ï –ü–û–î–ö–ê–°–¢–ê –ø–æ—Å–ª–µ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤
7. –ò–ì–ù–û–†–ò–†–£–ô –ø–µ—Ä–µ–≤–æ–¥—ã - —Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞—Ö —Å–ª—É—à–∞—Ç–µ–ª–µ–π –∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –º–µ–¥–∏—Ç–∞—Ü–∏—è—Ö

–í–ê–ñ–ù–û: –ò–©–ò –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–û–õ–ò–ß–ï–°–¢–í–û –í–û–ü–†–û–°–û–í –ò –ú–ï–î–ò–¢–ê–¶–ò–ô - –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π—Å—è 5-10, —Å—Ç–∞—Ä–∞–π—Å—è –Ω–∞–π—Ç–∏ –≤—Å–µ –∑–Ω–∞—á–∏–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –º–µ–¥–∏—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –≤ –ø–æ–¥–∫–∞—Å—Ç–µ.

–ö–†–ò–¢–ò–ß–ù–û: –î–ª—è –∫–∞–∂–¥–æ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π —Ç–µ–º—ã —É–∫–∞–∂–∏ –í–†–ï–ú–Ø –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–∏ [–≤—Ä–µ–º—è] –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ —Å–µ–≥–º–µ–Ω—Ç–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ —Å–ª—É—à–∞—Ç–µ–ª—è. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –≤–∏–¥–∏—à—å [125s][A] —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞, —Ç–æ –≤—Ä–µ–º—è = 125.

–ü—Ä–∏–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞:
- –í–æ–ø—Ä–æ—Å –æ—Ç —Å–ª—É—à–∞—Ç–µ–ª—è A: "[125s][A] –£ –º–µ–Ω—è –±–æ–ª–∏—Ç –≥–æ–ª–æ–≤–∞..."
- –í—Ä–µ–º—è –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞: 125 —Å–µ–∫—É–Ω–¥
- –ú–µ–¥–∏—Ç–∞—Ü–∏—è: "[1800s] –î–∞–≤–∞–π—Ç–µ –∑–∞–∫—Ä–æ–µ–º –≥–ª–∞–∑–∞ –∏ –Ω–∞—á–Ω–µ–º –º–µ–¥–∏—Ç–∞—Ü–∏—é..."
- –í—Ä–µ–º—è –¥–ª—è –º–µ–¥–∏—Ç–∞—Ü–∏–∏: 1800 —Å–µ–∫—É–Ω–¥`;

  const completion = await openai.chat.completions.create({
    model: "deepseek-chat",
    messages: [
      { role: "system", content: systemPrompt },
      { role: "user", content: userPrompt }
    ],
    temperature: 0.3,
    max_tokens: 4000,
  });

  const response = completion.choices[0].message.content.trim();
  
  // Parse JSON
  const jsonMatch = response.match(/\[[\s\S]*\]/);
  const jsonText = jsonMatch ? jsonMatch[0] : response;
  let questions = JSON.parse(jsonText);

  // Validate and fix
  questions = questions.filter(q => {
    return q && typeof q === 'object' && typeof q.title === 'string' && q.title.trim().length > 0;
  }).map(q => {
    let time = 0;
    const title = q.title.trim();
    const timeMatch = title.match(/\[(\d+)s?\]/);
    
    if (timeMatch) {
      time = parseInt(timeMatch[1]);
    } else if (typeof q.time === 'number' && !isNaN(q.time)) {
      time = Math.max(0, Number(q.time));
    } else if (typeof q.time === 'string' && !isNaN(Number(q.time))) {
      time = Math.max(0, Number(q.time));
    } else {
      // Fallback search strategies
      const questionText = title.toLowerCase();
      let matchingUtterance = utterances.find(u => {
        const utteranceText = (u.text || '').toLowerCase();
        return utteranceText.includes(questionText.substring(0, 15)) ||
               questionText.includes(utteranceText.substring(0, 15));
      });

      if (!matchingUtterance) {
        const questionWords = questionText.split(' ').filter(word => word.length > 3).slice(0, 3);
        matchingUtterance = utterances.find(u => {
          const utteranceText = (u.text || '').toLowerCase();
          return questionWords.some(word => utteranceText.includes(word));
        });
      }

      if (matchingUtterance) {
        time = Math.floor(matchingUtterance.start / 1000);
      }
    }

    return {
      title: title.replace(/\[\d+s?\]/g, '').trim(),
      time: Math.max(0, time)
    };
  });

  return questions;
}

async function main() {
  try {
    console.log('üöÄ Starting question generation script...');
    console.log('Supabase URL:', SUPABASE_URL);
    console.log('Supabase Key length:', SUPABASE_KEY ? SUPABASE_KEY.length : 0);
    console.log('DeepSeek Key length:', DEEPSEEK_API_KEY ? DEEPSEEK_API_KEY.length : 0);

    // 1. Get all RU transcripts (slugs only first)
    console.log('Fetching transcript slugs from Supabase...');
    const { data: transcripts, error: transcriptsError } = await supabase
      .from('transcripts')
      .select('episode_slug')
      .eq('lang', 'ru')
      .not('edited_transcript_data', 'is', null);

    if (transcriptsError) throw transcriptsError;
    console.log(`üìö Found ${transcripts.length} RU transcripts`);

    // 2. Get existing questions to filter out
    const { data: existingQuestions, error: questionsError } = await supabase
      .from('timecodes')
      .select('episode_slug')
      .eq('lang', 'ru');

    if (questionsError) throw questionsError;
    
    const episodesWithQuestions = new Set(existingQuestions.map(q => q.episode_slug));
    
    // 3. Filter episodes that need questions
    const episodesToProcess = transcripts.filter(t => !episodesWithQuestions.has(t.episode_slug));
    console.log(`üéØ Found ${episodesToProcess.length} episodes needing questions`);

    // 4. Process each episode
    for (const [index, episode] of episodesToProcess.entries()) {
      console.log(`\n[${index + 1}/${episodesToProcess.length}] Processing episode: ${episode.episode_slug}`);
      
      try {
        // Fetch transcript data for this episode
        const { data: transcriptData, error: transcriptError } = await supabase
          .from('transcripts')
          .select('edited_transcript_data')
          .eq('episode_slug', episode.episode_slug)
          .eq('lang', 'ru')
          .single();
        
        if (transcriptError) throw transcriptError;
        if (!transcriptData || !transcriptData.edited_transcript_data) {
            console.log('‚ö†Ô∏è No transcript data found, skipping');
            continue;
        }

        const questions = await generateQuestions(transcriptData.edited_transcript_data, 'ru');
        console.log(`‚úÖ Generated ${questions.length} questions`);

        // Save to DB
        const questionsToInsert = questions.map(q => ({
          episode_slug: episode.episode_slug,
          lang: 'ru',
          title: q.title,
          time: q.time
        }));

        const { error: insertError } = await supabase
          .from('timecodes')
          .insert(questionsToInsert);

        if (insertError) {
          console.error(`‚ùå Error saving questions for ${episode.episode_slug}:`, insertError);
        } else {
          console.log(`üíæ Saved questions to DB`);
        }

        // Add delay to avoid rate limits
        await new Promise(resolve => setTimeout(resolve, 2000));

      } catch (err) {
        console.error(`‚ùå Failed to process episode ${episode.episode_slug}:`, err.message);
      }
    }

    console.log('\n‚ú® Script completed!');

  } catch (error) {
    console.error('‚ùå Fatal error:', error);
  }
}

main();
